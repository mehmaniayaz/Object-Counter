{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from keras.models import Model\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as pyplot\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.data_augmentation import *\n",
    "from src.folder_preparation import *\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator,array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split original dataset into train and validation sets\n",
    "#### <font color='red'> only run once!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty_train_valid_split_directory('../simplifed-data-only-oranges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = Path('./split_data-only-oranges/train')\n",
    "val_dir = Path('./split_data-only-oranges/validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### augment all images by stitching them together\n",
    "#### <font color='red'> only run once!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# stitch_all_classes_in_root_directory(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### augment classes with insufficient stitched images automatically\n",
    "#### <font color='red'> only run once!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto_augment_classes_in_root_directory(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize data population for for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'> only run once!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #put only stitched and original images into a dataframe\n",
    "# df_class_stitched = dataframe_root_directory(root_dir=train_dir)\n",
    "# auto_augment_classes_in_root_directory(root_dir=train_dir)\n",
    "# #put only stitched and original images into a dataframe\n",
    "# df_class_all = dataframe_root_directory(root_dir=train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_stitched = pd.read_csv('image_list.csv')\n",
    "df_class_all = pd.read_csv('image_list_auto_stitched_original.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "ax = sns.countplot(x=\"class\",hue = 'type',data=df_class_stitched)\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "ax = sns.countplot(x=\"class\",hue = 'type',data=df_class_all)\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "img_height = 50\n",
    "img_width = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    seed = 123,\n",
    "    image_size = (img_height,img_width),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    seed=123,\n",
    "    image_size=(img_height,img_width),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for images,labels in train_ds:\n",
    "    for i in range(4):\n",
    "        ax = plt.subplot(2,2,i+1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "normalized_train_ds = train_ds.map(lambda x, y: (normalization_layer(x),y))\n",
    "normalized_val_ds = val_ds.map(lambda x, y: (normalization_layer(x),y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configure dataset for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = normalized_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = normalized_val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "model = tf.keras.Sequential([\n",
    "#     layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    layers.Conv2D(32,3,activation='relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(32,3,activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32,3,activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128,activation='relu'),\n",
    "    layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.apply(tf.data.experimental.ignore_errors())\n",
    "val_ds = val_ds.apply(tf.data.experimental.ignore_errors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('save_your_model_here.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# model_new = load_model('auto_stitched_orig_scondModel_round1.h5')\n",
    "# model_new.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model=model_new,to_file='../disp-images/architecture.png',show_shapes=True,\n",
    "          show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz\n",
    "\n",
    "ann_viz(model_new,title=\"CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([x[1].numpy() for x in list(val_ds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = np.array(list(np.concatenate(labels, axis=0 )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_true=ground_truth, y_pred=predicted_classes)  # shape=(12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_labels = list(np.sort(list(map(int,class_names))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(confusion_matrix,columns=cm_labels,index = cm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(font_scale=1.4)\n",
    "plt.figure(figsize=(10,10))\n",
    "ax=sns.heatmap(df_cm.divide(df_cm.sum(axis=1),axis='rows'),\n",
    "           cmap='Blues',\n",
    "           annot=True,\n",
    "              fmt='0.2f')\n",
    "ax.set(xlabel='Predictions',ylabel='Truths')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('../disp-images/validation_confusionMatrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = model.predict_generator(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes_train = np.argmax(predictions_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = np.array([x[1].numpy() for x in list(train_ds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_train = np.array(list(np.concatenate(labels_train, axis=0 )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_train = metrics.confusion_matrix(y_true=ground_truth_train, y_pred=predicted_classes_train)  # shape=(12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_labels = list(np.sort(list(map(int,class_names))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_train = pd.DataFrame(confusion_matrix_train,columns=cm_labels,index = cm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(font_scale=1.4)\n",
    "plt.figure(figsize=(10,10))\n",
    "ax=sns.heatmap(df_cm_train.divide(df_cm_train.sum(axis=1),axis='rows'),\n",
    "           cmap='Blues',\n",
    "           annot=True,\n",
    "              fmt='0.2f')\n",
    "ax.set(xlabel='Predictions',ylabel='Truths')\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('../disp-images/training_confusionMatrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualizing training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(1,epochs+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "# plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training')\n",
    "plt.plot(epochs_range, val_acc, label='Validation')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('../disp-images/training_validation_accuracy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_new.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model_new.layers[0]\n",
    "print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filters,biases = layer.get_weights()\n",
    "print(layer.name,filters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize filter shapes\n",
    "for layer in model_new.layers:\n",
    "    # check for convolutional layer\n",
    "    if 'conv' not in layer.name:\n",
    "        continue\n",
    "    # get filter weights\n",
    "    filters, biases = layer.get_weights()\n",
    "    print(layer.name, filters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_min, f_max = filters.min(),filters.max()\n",
    "filters = (filters-f_min)/(f_max-f_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "# plot first few filters\n",
    "n_filters, ix = 6, 1\n",
    "for i in range(n_filters):\n",
    "    f = filters[:, :, :, i]\n",
    "    # plot each channel separately\n",
    "    for j in range(3):\n",
    "        # specify subplot and turn of axis\n",
    "        ax = pyplot.subplot(n_filters, 3, ix)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        # plot filter channel in grayscale\n",
    "        pyplot.imshow(f[:, :, j])\n",
    "        ix += 1\n",
    "plt.tight_layout()\n",
    "plt.savefig('../disp-images/activation_filters.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='purple'>observation</font>\n",
    "### <font color='purple'>*we see that light directions have been random which is consistent with our data gathering procedure*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.figure(figsize=(10,10))\n",
    "image_batch, labels_batch = next(iter(normalized_train_ds))\n",
    "first_image = image_batch[0]\n",
    "plt.imshow(first_image)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('../disp-images/sample_image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all convolutional layers\n",
    "for i in range(len(model.layers)):\n",
    "    layer=model.layers[i]\n",
    "    if 'conv' not in layer.name:\n",
    "        continue\n",
    "    # summarize output shape\n",
    "    print(i, layer.name, layer.output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fm=Model(inputs=model_new.inputs,outputs=model_new.layers[0].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = expand_dims(first_image,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_maps=model_fm.predict(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "dim1=8\n",
    "dim2=4\n",
    "ix = 1\n",
    "for _ in range(dim1):\n",
    "    for _ in range(dim2):\n",
    "        # specify subplot and turn of axis\n",
    "        ax = pyplot.subplot(dim1, dim2, ix)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        # plot filter channel in grayscale\n",
    "        pyplot.imshow(feature_maps[0, :, :, ix-1])\n",
    "        ix += 1\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize all blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine model to output right after the first hidden layer\n",
    "ixs = [0,2,4]\n",
    "outputs = [model_new.layers[i].output for i in ixs]\n",
    "model_fm = Model(inputs=model_new.inputs, outputs=outputs)\n",
    "# get feature map for first hidden layer\n",
    "feature_maps = model_fm.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dim1=4\n",
    "dim2=2\n",
    "ix = 1\n",
    "counter=0\n",
    "for fmap in feature_maps:\n",
    "    counter+=1\n",
    "    plt.figure(figsize=(20,20))\n",
    "    # plot all 64 maps in an 8x8 squares\n",
    "    ix = 1\n",
    "    for _ in range(dim1*dim2):\n",
    "        # specify subplot and turn of axis\n",
    "        ax = pyplot.subplot(dim1, dim2, ix)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        # plot filter channel in grayscale\n",
    "        pyplot.imshow(fmap[0, :, :, ix-1])\n",
    "        ix += 1\n",
    "    print('---------------------------------------------')\n",
    "    # show the figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../disp-images/feature_visualization'+str(counter)+'.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "object_counter",
   "language": "python",
   "name": "object_counter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
